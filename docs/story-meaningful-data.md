# Part 1: The story about data - meaningful data made easily available
Hi all! My name is Steffan Sørenes, and I work as a senior IT analyst in Equinor. I have been working with plant specific industrial IT systems since I started in Statoil in 2011. The last 4-5 years, a focus for me has been to make more meaningful data from our assets easier available – in a secure manner. Why? Below is the first part of my personal reflections around this topic.

Digitalization is on everyone’s lips these days, but at Equinor, it is already part of our DNA. We are now putting our industrial strength behind digitalization, investing 1-2 billion NOK by 2020 – on top of existing IT investments. You can ready more about our ambitions, approach and digital roadmap here: https://www.equinor.com/no/hvordan-og-hvorfor/digitalisation-in-our-dna.html

## Data-driven operations
One of the focus areas and programs in our digital roadmap is data-driven operations. This is about using data to maximize asset value through production optimization and maintenance improvements. Dozens of articles and papers have been written about data-driven organizations, and how to really become data-driven, but for me it boils down to the following.

1. **Data!** This is obvious, you need data to be available if you want to run your business based on data. The phrase “data locked down in silos” is often mentioned in this context as a challenge for the digital roadmap. The data is tightly linked to all the applications across the value chain and using the data in another context beyond its original purpose is often a challenge. The variation of technical interfaces, performance, documentation, knowledge, and data management in all applications are significant. Equinor is building OMNIA – The Data Platform that enables our digital roadmap. We are going from silos of data, to one common data platform for the entire Equinor value chain, and making data available in OMNIA is a key activity. See more information about OMNIA in this article https://www.linkedin.com/pulse/meet-omnia-statoil-data-platform-enables-our-digital-larsen/ written by the CIO and SVP Corporate IT at Equinor, Åshild Hanne Larsen.

2. **Context!** Data that makes sense, data people trust and understand, and data combined across silos. Making (e.g. replicating) data from on-premises applications to one and/or several data store(s) in a cloud data platform is only one step in the direction of becoming data-driven. Lifting data to one common platform provides many advantages, but, and this is important and my focus in this article, the challenge to understand the data, and really make sense out of the data is to my opinion still the same. The data needs to be put into a context where data is combined across silos and data stores. I prefer saying “connecting the dots” (as Steve Jobs once said). This is and has been a challenge in the on-premises world / “classic IT” and will also be a challenge in the cloud world if this is not addressed properly from the beginning. When you are going to solve a problem, find new business insights, and/or do more advanced analysis we need to make sure it is easy to query and ask questions across the disparate data stores and data sets. This will not happen by itself by just lifting data to the cloud. The value in the data stored in one data store is there, but the value in the data when you connect all the dots and look at them together is a whole different story.

3. **Analysis and visualization!** The first two steps are about making meaningful data easier available, i.e. data that you from your context and perspective understands and trusts, and data that is combined in a way that makes sense for you is easily available through standardized and well-defined interfaces in the data platform. When this is in place, let the people with the domain knowledge, the people with hands-on equipment experience, the scientists, the engineers, the economists, the people with great ideas, the innovators – let them free, let them analyze, let them run code on this data – let them find insight that supports the objective of digital roadmap. Move more of the focus and time spent to finding data, making it available, understanding it, cleaning it – to using it; beyond its original purpose.

4. **Business decisions!** The final step is to make business decisions based on the data and the results from the data analysis. This is when you start to see business value effect.
My personal experience is that making data available as described in point 1 is a challenging task, but the technical landscape is quite well-known and mature. We have only started to see the beginning of analyzing and visualizing data and insights as described in point 3, this area has a lot of potential, and in my opinion point 2 is a key enabler. The task in point 2 is challenging due to technical and non-technical reasons. The technical landscape, especially in cloud platforms (PaaS) and cloud software (SaaS) is more unknown, to me at least, and the success of this task really depends on your data, i.e. data quality and data management.

## Example of data stores and types of data
Putting data into a context has proven to be valuable both for simply finding the data you need, and for utilizing the data for new purposes. Below is examples of typical data stores and types of data that end users meet.  

Imagine you are a data scientist that is trying to build a machine learning model for predicting failure on a compressor unit on asset X. Let’s say you, as a step one, need all timeseries data for the last two years associated to this specific equipment. You need this data in a way that you can use it as input to your machine learning model.  

**Let me hear your input:** Where would you start to find this data? What is your expectations?

### Technical information – engineering data
On off- and onshore assets, all physical equipment is tagged with an identifier called a tag number. Oil & gas companies typically have a master register for tagged equipment on each asset, and I assume this is something most asset-heavy industries have and are familiar with as well. This is the system where you find the technical information, the engineering data of your asset like basic tag metadata, associated technical documents, 3D drawings, P&IDs, SCDs etc. The purpose of tag numbers is to support safe operation and maintenance on the assets. This means that the physical instrument field equipment on the asset which (at the end) is the source of the timeseries data we are looking for is tagged with a tag number. Knowing this tag number is a key to find the data. The importance of a tag master data store (that everybody agrees on is the master) with good data quality that people trust, and descriptive metadata is huge in this process. This type of data store holds a lot of data that is valuable and important in various contexts for various purposes in the digital roadmap.

The piping & instrumentation diagrams (P&IDs) shows the piping and vessels in a process flow together with instrumentation and control devices. This is an important tool for many, especially process engineers. The P&IDs puts the instrumentation in a context. The P&ID is associated to an asset, a system (e.g. gas compression), it is mainly centered around a main equipment unit (e.g. the 1st stage compressor unit train A), and it includes the instrumentation tags along the process flow illustrated in the specific P&ID. Normally, due to complexity, there are often several “layers” of P&ID drawings, each showing parts of the same equipment, but tailored for a specific purpose or audience. This means that one specific main equipment unit might be a part of several P&IDs.

### Timeseries database / Historian
The next step after the relevant physical instrumentation tags are found is to get the real measurements that can be analyzed by software code. In the oil & gas industry, at least, a common architecture and approach is to push these measurements / timeseries data to the enterprise / office network and store them in a specialized timeseries database, often called Historian, where both historical timeseries data and online / near real-time timeseries data is made available to end users through various visualization tools, interfaces and APIs. The timeseries data flowing into these databases are coming from systems like safety and automation systems, metering systems, and several condition monitoring systems across disciplines on the assets, and the data is typically collected through interfaces such as OPC or vendor-specific proprietary interfaces.

If you know the tag number of a specific main equipment unit, such as the 1st stage gas compressor on asset X with tag number 23KA1234, it would make sense, at least for me, to search for this tag number in the timeseries database to get all measurements from instrumentation that has a reference to this main equipment unit. However, this is normally not the case. The timeseries database is not storing main equipment unit tags. The timeseries database is storing instrument field equipment tags represented as a flat list of fields like tag number, description, measurement value, engineering unit, timestamp and a quality flag. The main equipment unit itself is not generating timeseries data, that’s the job of the instrumentation that is tagged separately. Therefore, the timeseries database itself will usually not store the main equipment unit tags nor any references to instrumentation tags. However, several Historian vendors have separate tools and frameworks that are designed to build asset hierarchies and make relations between tags to provide a context and a meaning to the data. The process to build such a hierarchy and context is for many reasons quite time consuming. An important data input to this process is the systems and types of data mentioned earlier, the tag master, the P&IDs, SCDs etc. With assistance from domain experts, these systems and documents are studied to understand the equipment and the process flow on the assets, and then using this understanding and insight to establish one and/or several hierarchies and contexts on top of the timeseries data which is usually organized as a flat list of tags with basic properties.  

### To summarize the example
- Tag numbers are a key identification of physical equipment on the assets. Knowing the tag numbers of the physical things you want data from is a benefit. Some people just know these tag numbers by experience, others must look for them in various data stores which takes time.

- An agreed tag master that everybody in the organization trust is important. It is challenging to connect the dots if the same physical equipment is tagged differently or identified differently in different data stores without a central mapping register.

- A piece of equipment or process has subsets of data and metadata across several data stores that together helps you understand what the data represents. For instance, you see a tag number 23PT1234A with description “PRESSURE TRANSMITTER” and a value, engineering unit and timestamp. From the tag number itself and the description, we know this is a pressure transmitter on the gas compression system, but on which compressor? What pressure does it measure? Something in the compressor unit itself? Something on the way into the compressor unit? Something on the way out from the compressor unit?

- The P&IDs provides you some insight, and it is in general trusted by the engineers. However, the process flow semantics (e.g. this sensor is measuring inlet and this sensor is measuring outlet) is often not available for consumption by third party software through open and well-defined APIs.

## Not one system to rule them all
As mentioned, the data about an equipment or process is not stored in only one data store. The data about a “thing” is spread across several data stores each serving a specific purpose in the overall picture. One single piece of equipment might have associated:

- Real time and historical timeseries data stored in timeseries databases / Historians
- Maintenance activities and maintenance history in the ERP system
- Technical information (tag metadata, technical documents, P&IDs, 3D drawings etc). stored in the engineering master system
- Production data in the production reporting system
- Detailed diagnostics data in expert automation systems on the assets that is not made available on the enterprise network or in the cloud (for several reasons)
- “Cloud-born” data. When organizations now move data to the cloud to analyze it, the results and insights of this is also data we want to store and manage. These results might be valuable for other users in other contexts. This is data born in the cloud.
.. and the list goes on.  
This fact and reality answers the question on why focus on point 2 as described in the beginning of this article is important. I expect there will be more and more questions asked by the engineers and scientists that can only be answered by connecting the data across these data stores.

## Asset hierarchy – Asset modelling
The word “asset hierarchy” and/or “asset model / asset modelling” is often used in the oil & gas industry, and in other asset-heavy industries as well I assume. It is for me basically a model, a structure about your assets, how the assets are organized and how the assets relate to each other. It is the meaning of data for your specific domain and context.

In my next article, I will dive more into the topic of asset hierarchies / asset models.

Any input and comments?
